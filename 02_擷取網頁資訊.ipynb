{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 創建 HTML\n",
    "我們先自己寫好 HTML，把它當成網站上爬回來的內容，再透過 BeautifulSoup 取出裡面的資料\n",
    "\n",
    "[HTML 教學](https://www.w3school.com.cn/html/index.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>網頁標題</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id=\"header\">\n",
    "      <a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
    "        PTT\n",
    "      </a>\n",
    "    </div>\n",
    "    <div class=\"images\">\n",
    "      <img src=\"0.png\" />\n",
    "      <img src=\"01.png\" />\n",
    "      <img src=\"02.png\" />\n",
    "      <img src=\"03.png\" />\n",
    "      <img src=\"11.png\" />\n",
    "      <img src=\"12.png\" />\n",
    "      <img src=\"13.png\" />\n",
    "      <img src=\"01111.png\" />\n",
    "    </div>\n",
    "    <div id=\"container\">\n",
    "      <h2 id=\"title\">八卦版</h2>\n",
    "      <div class=\"article a1\">\n",
    "        <h3 class=\"title t1\">文章標題1</h3>\n",
    "        <div class=\"author\">作者1</div>\n",
    "        <div class=\"date\">11/01</div>\n",
    "      </div>\n",
    "      <div class=\"article a2\">\n",
    "        <h3 class=\"title t2\">文章標題2</h3>\n",
    "        <div class=\"author\">作者2</div>\n",
    "        <div class=\"date\">11/02</div>\n",
    "      </div>\n",
    "      <div class=\"article a3\">\n",
    "        <h3 class=\"title t3\">文章標題3</h3>\n",
    "        <div class=\"author\">作者3</div>\n",
    "        <div class=\"date\">11/03</div>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div id=\"footer\">\n",
    "      <p class=\"address\">臺北市信義區</p>\n",
    "      <p class=\"copyright\">&copy; Copyright 2019</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "我們從網站上面爬取下來的資料其實只是一個字串，程式並不知道這些 HTML 代表什麼意思，所以我們透過 Beautiful Soup 幫我們解析頁面，可以方便地取出我們要的資訊。\n",
    "\n",
    "[Beautiful Soup 官方文檔](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)\n",
    "\n",
    "[parsers 介紹](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#id12)\n",
    "\n",
    "[parsers 之間的差別](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#id53)\n",
    "\n",
    "官方推薦使用 lxml 解析器，速度較快，所以接下來的範例都是使用 lxml。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 BeautifulSoup 解析我們創建的 html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>網頁標題</title>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"header\">\n",
       "<a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
       "        PTT\n",
       "      </a>\n",
       "</div>\n",
       "<div class=\"images\">\n",
       "<img src=\"0.png\"/>\n",
       "<img src=\"01.png\"/>\n",
       "<img src=\"02.png\"/>\n",
       "<img src=\"03.png\"/>\n",
       "<img src=\"11.png\"/>\n",
       "<img src=\"12.png\"/>\n",
       "<img src=\"13.png\"/>\n",
       "<img src=\"01111.png\"/>\n",
       "</div>\n",
       "<div id=\"container\">\n",
       "<h2 id=\"title\">八卦版</h2>\n",
       "<div class=\"article a1\">\n",
       "<h3 class=\"title t1\">文章標題1</h3>\n",
       "<div class=\"author\">作者1</div>\n",
       "<div class=\"date\">11/01</div>\n",
       "</div>\n",
       "<div class=\"article a2\">\n",
       "<h3 class=\"title t2\">文章標題2</h3>\n",
       "<div class=\"author\">作者2</div>\n",
       "<div class=\"date\">11/02</div>\n",
       "</div>\n",
       "<div class=\"article a3\">\n",
       "<h3 class=\"title t3\">文章標題3</h3>\n",
       "<div class=\"author\">作者3</div>\n",
       "<div class=\"date\">11/03</div>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"footer\">\n",
       "<p class=\"address\">臺北市信義區</p>\n",
       "<p class=\"copyright\">© Copyright 2019</p>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得網頁標籤\n",
    "BeautifulSoup 已經幫我們解析好頁面，接下來我們使用 BeautifulSoup 提供的方法來取得頁面資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>網頁標題</title>\n",
      "<a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
      "        PTT\n",
      "      </a>\n"
     ]
    }
   ],
   "source": [
    "# 抓取 title 資訊\n",
    "# 注意: 這裡的 title 指的是 <head></head> 裡面的 <title>網頁標題</title>\n",
    "# 並不是 <h2 id=\"title\">八卦版</h2> 與 <h3 class=\"title t1\">文章標題1</h3>\n",
    "print(soup.title)\n",
    "\n",
    "# 抓取所有 <a></a> 內容\n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得標籤內的資訊\n",
    "上面的方式會取得整個標籤，可是我們通常只會需要取裡面的文字，或者標籤上的連結\n",
    "- 如果要取得標籤裡面的文字，可以使用 .text\n",
    "- 如果要取得標籤上的參數可以使用 .get['參數名稱'] 或者 ['參數名稱']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "網頁標題\n",
      "https://test.com.tw/logo-link\n",
      "https://test.com.tw/logo-link\n"
     ]
    }
   ],
   "source": [
    "# 取得標籤內的文字\n",
    "print(soup.title.text)\n",
    "\n",
    "# 取得標籤上的參數\n",
    "# 以下程式取得 a 標籤的 href 資料\n",
    "# <a href=\"https://test.com.tw/logo-link\">PTT</a>\n",
    "print(soup.a.get(\"href\"))\n",
    "print(soup.a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 find 取得單筆內容\n",
    "我們可以用不同方式來選取內容\n",
    "- 標籤 -> div, a, h2, h3\n",
    "- id\n",
    "- class\n",
    "\n",
    "取得 id, class 不只有一種寫法，可以挑選一個自己喜歡的語法就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"title\">八卦版</h2>\n",
      "<h2 id=\"title\">八卦版</h2>\n",
      "<h2 id=\"title\">八卦版</h2>\n",
      "<h2 id=\"title\">八卦版</h2>\n",
      "--------\n",
      "<h3 class=\"title t1\">文章標題1</h3>\n",
      "<h3 class=\"title t1\">文章標題1</h3>\n",
      "<h3 class=\"title t1\">文章標題1</h3>\n",
      "<h3 class=\"title t1\">文章標題1</h3>\n",
      "<h3 class=\"title t1\">文章標題1</h3>\n"
     ]
    }
   ],
   "source": [
    "# 以下指令都可以取得 <h2 id=\"title\">八卦版</h2>\n",
    "print(soup.find(\"h2\"))\n",
    "print(soup.find(id=\"title\"))\n",
    "print(soup.find(\"h2\", id=\"title\"))\n",
    "print(soup.find(\"h2\", {\"id\": \"title\"}))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "# 以下指令都可以取得 <h3 class=\"title t1\">文章標題1</h3>\n",
    "print(soup.find(\"h3\"))\n",
    "print(soup.find(class_=\"title\"))\n",
    "print(soup.find(\"h3\", class_= \"title\"))\n",
    "print(soup.find(\"h3\", {\"class\": \"title\"}))\n",
    "print(soup.find(\"h3\", \"title\")) # 沒有特別指定使用 id 或 class，預設就是使用 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 find_all 取得多筆內容\n",
    "```\n",
    "使用 find 只能取得一個元素，如果有多個相同的條件元素，只會取第一個\n",
    "可是大多數的情況我們都會一次取多個元素(如: 文章列表)，這時候就可以用 find_all 來達成\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"title t1\">文章標題1</h3>, <h3 class=\"title t2\">文章標題2</h3>, <h3 class=\"title t3\">文章標題3</h3>]\n"
     ]
    }
   ],
   "source": [
    "# 可將上面任一項目從 find 改成 find_all\n",
    "\n",
    "# id, class 在 html 的使用上其實有不同的含義\n",
    "# id 代表唯一的，所以只會出現一次\n",
    "# class 則是會有多個，就像這邊每篇文章的標題都會有 class=\"title\"\n",
    "\n",
    "print(soup.find_all(class_=\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"title t1\">文章標題1</h3>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 在一個標籤上通常會有多個 class\n",
    "# 我們可以取得同時擁有 title 與 t1 兩個 class 的元素\n",
    "print(soup.find_all(class_=\"title t1\"))\n",
    "\n",
    "# 如果設定的 class 順序與 html 上不同就抓不到值\n",
    "# html 上的 class 順序是 title t1，所以我們設定 t1 title 會抓不到這個元素\n",
    "print(soup.find_all(class_=\"t1 title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 透過 select 使用 css 選擇器的方式做篩選"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "其實撰寫 css 的概念跟和上面範例選取元素很像\n",
    "只是 css 是附加樣式上去改變網頁外觀\n",
    "詳情可以參考 CSS 教程(https://www.w3school.com.cn/css/index.asp)\n",
    "\n",
    "在 css 要選取 id 時，開頭為 #\n",
    "如: #header\n",
    "\n",
    "在 css 要選取 class 時，開頭為 .\n",
    "如: .title\n",
    "\n",
    "在 css 要選取標籤時，可直接使用標籤名稱\n",
    "如: div, h1, a\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"title t1\">文章標題1</h3>, <h3 class=\"title t2\">文章標題2</h3>, <h3 class=\"title t3\">文章標題3</h3>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.select(\".title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"title t1\">文章標題1</h3>]\n",
      "[<h3 class=\"title t1\">文章標題1</h3>]\n"
     ]
    }
   ],
   "source": [
    "# 可以不用管 html 上的 class 順序\n",
    "print(soup.select(\".t1.title\"))\n",
    "print(soup.select(\".a1.article .t1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將所有選到的項目一個個取出來\n",
    "當取多個項目時，項目會被放在陣列裡面，我們透過迴圈把一個個的項目取出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文章標題1\n",
      "文章標題2\n",
      "文章標題3\n"
     ]
    }
   ],
   "source": [
    "# soup.select(\".title\") 可以取到三個包含 .title 的元素\n",
    "# 透過迴圈將一個個元素取出來\n",
    "\n",
    "# 第一個迴圈，item 這個變數會被放入第一個元素\n",
    "# 第二個迴圈，item 這個變數會被放入第二個元素\n",
    "#  以此類推...\n",
    "for item in soup.select(\".title\"):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 re\n",
    "這個套件讓我們可以使用 [Regex (正規表示式)](https://docs.python.org/zh-cn/3/library/re.html)\n",
    "\n",
    "我們會透過正規表示式來取出與我們設定條件相匹配的內容(如: 結尾為.png)\n",
    "\n",
    "一般在填表單時，也會用它來驗證使用者的輸入資訊是否符合格式(身分證字號、信箱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"title t1\">文章標題1</h3>, <h3 class=\"title t2\">文章標題2</h3>, <h3 class=\"title t3\">文章標題3</h3>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 找出名稱包含 tle 的 class\n",
    "print(soup.find_all(class_=re.compile(\"tle\")))\n",
    "\n",
    "# ^ 代表比對開頭，也就是找出開頭為 tle 的 class (這邊沒有這樣的項目)\n",
    "print(soup.find_all(class_=re.compile(\"^tle\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png\n",
      "01.png\n",
      "02.png\n",
      "03.png\n",
      "11.png\n",
      "12.png\n",
      "13.png\n",
      "01111.png\n"
     ]
    }
   ],
   "source": [
    "# $ 代表比對結尾，也就是找出所有 .png 結尾的圖片\n",
    "# . 在正規表示式中也是一個語法，可是在這個範例中他只是 .png 的字串而已\n",
    "# 在 . 前面加上 \\ 代表不啟用原本正規表示式的功能，它只是個普通字串\n",
    "for img in soup.find_all('img', {'src': re.compile('\\.png$')}):\n",
    "    print(img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png\n",
      "01.png\n",
      "02.png\n",
      "03.png\n",
      "01111.png\n"
     ]
    }
   ],
   "source": [
    "# 找出包含 '0' 且結尾為 .png 的圖片\n",
    "# . 代表任意字符\n",
    "# * 代表前面的字符可以出現 0 次或多次\n",
    "# .* 代表可以隨意放入多個任何字符\n",
    "# 所以在 0 與 .png 中間加入任意的內容也都可以被選取出來(不包含 0 的內容就沒有被取到)\n",
    "for img in soup.find_all('img', {'src': re.compile('0.*\\.png$')}):\n",
    "    print(img['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask\n",
    "Flask 是很輕量的網頁框架，只要短短幾後行指令就可以寫出網頁。\n",
    "\n",
    "上面我們是直接寫好 HTML 的內容，再透過 Beautiful Soup 解析，可是真實情況下我們必須從網頁上把這些 HTML 取下來，因此，我們使用 Flask 實際架起網頁，再透過套件 requests 取得 HTML，模擬真實爬蟲的情境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 架個 hello world 頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Nov/2019 14:15:03] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# 執行後，會開啟伺服器\n",
    "# 接著到瀏覽器開啟 http://127.0.0.1:5000/ 就可以看到網頁\n",
    "# 執行伺服器後，會持續運行著\n",
    "# 要關掉伺服器可以點擊 jupyter 選單，Run 右邊的方框\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 透過 Flask 將前面的 HTML 範例變成真正的網頁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "執行伺服器後，會持續運行著\n",
    "\n",
    "這樣在 jupyter 上就無法運行其他的區塊\n",
    "\n",
    "所以建議把以下程式放到 .py 上執行\n",
    "\n",
    "再到瀏覽器開啟 http://127.0.0.1:5000/ 就可以看到網頁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "以下的程式已有放在 01_flask_web/app.py 裡\n",
    "使用 vs code 開啟課程資料 crawler_20191122 (將資料夾拖拉進去就可以)\n",
    "按 ctrl + ` 開啟終端機\n",
    "執行 python 01_flask_web/app.py 就可以啟動伺服器\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Nov/2019 14:51:27] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"\"\"\n",
    "    <html>\n",
    "      <head>\n",
    "        <title>網頁標題</title>\n",
    "      </head>\n",
    "      <body>\n",
    "        <div id=\"header\">\n",
    "          <a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
    "            PTT\n",
    "          </a>\n",
    "        </div>\n",
    "        <div class=\"images\">\n",
    "          <img src=\"0.png\" />\n",
    "          <img src=\"01.png\" />\n",
    "          <img src=\"02.png\" />\n",
    "          <img src=\"03.png\" />\n",
    "          <img src=\"11.png\" />\n",
    "          <img src=\"12.png\" />\n",
    "          <img src=\"13.png\" />\n",
    "          <img src=\"01111.png\" />\n",
    "        </div>\n",
    "        <div id=\"container\">\n",
    "          <h2 id=\"title\">八卦版</h2>\n",
    "          <div class=\"article a1\">\n",
    "            <h3 class=\"title t1\">文章標題1</h3>\n",
    "            <div class=\"author\">作者1</div>\n",
    "            <div class=\"date\">11/01</div>\n",
    "          </div>\n",
    "          <div class=\"article a2\">\n",
    "            <h3 class=\"title t2\">文章標題2</h3>\n",
    "            <div class=\"author\">作者2</div>\n",
    "            <div class=\"date\">11/02</div>\n",
    "          </div>\n",
    "          <div class=\"article a3\">\n",
    "            <h3 class=\"title t3\">文章標題3</h3>\n",
    "            <div class=\"author\">作者3</div>\n",
    "            <div class=\"date\">11/03</div>\n",
    "          </div>\n",
    "        </div>\n",
    "        <div id=\"footer\">\n",
    "          <p class=\"address\">臺北市信義區</p>\n",
    "          <p class=\"copyright\">&copy; Copyright 2019</p>\n",
    "        </div>\n",
    "      </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 requests 取得網頁上的資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們已經了把網頁架起來了，接下來就是要把資料抓下來\n",
    "\n",
    "我們伺服器的位址是在 http://127.0.0.1:5000/\n",
    "        \n",
    "所以執行 requests.get('http://127.0.0.1:5000/') 就可以抓到內容\n",
    "\n",
    "當你想要抓其他網頁的資料，只要更換網址就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <html>\n",
      "      <head>\n",
      "        <title>網頁標題</title>\n",
      "      </head>\n",
      "      <body>\n",
      "        <div id=\"header\">\n",
      "          <a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
      "            PTT\n",
      "          </a>\n",
      "        </div>\n",
      "        <div class=\"images\">\n",
      "          <img src=\"0.png\" />\n",
      "          <img src=\"01.png\" />\n",
      "          <img src=\"02.png\" />\n",
      "          <img src=\"03.png\" />\n",
      "          <img src=\"11.png\" />\n",
      "          <img src=\"12.png\" />\n",
      "          <img src=\"13.png\" />\n",
      "          <img src=\"01111.png\" />\n",
      "        </div>\n",
      "        <div id=\"container\">\n",
      "          <h2 id=\"title\">八卦版</h2>\n",
      "          <div class=\"article a1\">\n",
      "            <h3 class=\"title t1\">文章標題1</h3>\n",
      "            <div class=\"author\">作者1</div>\n",
      "            <div class=\"date\">11/01</div>\n",
      "          </div>\n",
      "          <div class=\"article a2\">\n",
      "            <h3 class=\"title t2\">文章標題2</h3>\n",
      "            <div class=\"author\">作者2</div>\n",
      "            <div class=\"date\">11/02</div>\n",
      "          </div>\n",
      "          <div class=\"article a3\">\n",
      "            <h3 class=\"title t3\">文章標題3</h3>\n",
      "            <div class=\"author\">作者3</div>\n",
      "            <div class=\"date\">11/03</div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div id=\"footer\">\n",
      "          <p class=\"address\">臺北市信義區</p>\n",
      "          <p class=\"copyright\">&copy; Copyright 2019</p>\n",
      "        </div>\n",
      "      </body>\n",
      "    </html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "resp = requests.get('http://127.0.0.1:5000/')\n",
    "\n",
    "# status_code == 200 代表成功從伺服器接收資料\n",
    "# https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81\n",
    "if resp.status_code == 200:\n",
    "    print(resp.text) # 也可以在 http://127.0.0.1:5000/ 按右鍵『檢視網頁原始碼』看到以下的內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 BeautifulSoup 解析內容，取出資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>網頁標題</title>\n",
      "<a class=\"logo\" href=\"https://test.com.tw/logo-link\">\n",
      "            PTT\n",
      "          </a>\n",
      "[<h3 class=\"title t1\">文章標題1</h3>, <h3 class=\"title t2\">文章標題2</h3>, <h3 class=\"title t3\">文章標題3</h3>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.a)\n",
    "print(soup.select(\".title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "- 可以試著使用 requests 去爬取其他網頁看看\n",
    "- 再使用 BeautifulSoup 取得想要的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
